{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Predicting Daily Bike Rentals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A bike share system is a service in which bicycles are made available for shared use to individuals on a short term basis for a price or free [source](https://en.wikipedia.org/wiki/Bicycle-sharing_system). The dataset related to the bike rental has been realized by Hadi Fanaee-T at the University of Porto, that can be found [here](http://archive.ics.uci.edu/ml/datasets/Bike+Sharing+Dataset).\n",
    "The goal of this project is to predict the total number of bikes people rented in a given hour.\n",
    "\n",
    "To this end different machine learning techniques will be developed, in particular Decison Tree, Random Forest and AdaBoost along with the evaluation of their performances in order to select the one that better describes the considered dataset and that can make the most accurate prediction.\n",
    "\n",
    "\n",
    "The project will be structured as follows:\n",
    "\n",
    "1) Analysis and Data Preparation\n",
    "\n",
    "2) Definition of useful functions (e.g. for cross-validation, test/train split, computation of metrics of interest etc.)\n",
    "\n",
    "3) Models Evaluation\n",
    "\n",
    "4) Analysis of features importance\n",
    "\n",
    "5) Robustness Analysis\n",
    "    \n",
    "6) Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis and Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You will need to import some useful packages for the exercises. You can write them here.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now import the dataset and take a look at it to have a better understanding of the features and to identify the response variable. Write down some comments about them.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the dataset\n",
    "\n",
    "# display the first few row in order to take a look at the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Consider the type of each feature and identify the one/s that may not work for a machine learning framework. Would it be useful to convert it/them or should we drop it/them?\n",
    "Moreover think about the 'yr' column: could we also drop this feature?**\n",
    "\n",
    "\n",
    "**Take now a look at the *instant* column: do you think it would be helpful in predicting the bike rental? Why?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate now the distribution of the total rentals and comment the results.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build an histogram of the \"cnt\" column\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Another way to select the most useful features for your machine learning problem is to evaluate the correlation analysis: features that are highly correlated between them bring redundant information into the analysis, so it could be useful to drop one of them. Moreover it is also useful to check which features are more correlated with the response variable.**\n",
    "\n",
    "**Perform a correlation analysis and evaluate the features which are more correlated with the response variable and ask yourself if it would be fair for your analysis to keep them. Why?**\n",
    "\n",
    "**Take now a look at the features that are highly correlated between them: which one could we drop?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipulate Columns to Extract Useful Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now manipulate the hr column that contains rental hours, from 1 to 24. In particular you can put together a specific time interval to identify a specific moment of the day (e.g. morning from 6am to 12pm) that can be associated with an identifier. One idea is the following:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**- assign 1 if the hour is from 6 to 12**\n",
    "\n",
    "**- assign 2 if the hour is from 12 to 18**\n",
    "\n",
    "**- assign 3 if the hour is from 18 to 24**\n",
    "\n",
    "**- assign 4 if the hour is from 0 to 6**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use the function .describe() to inspect the values of each column: are they consistent in terms of values  or should we normalize them?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Definition of useful functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In this section you are asked to write some useful functions:**\n",
    "\n",
    "**Cross_Val(splits, features, target, model)**: \n",
    "\n",
    "This function computes the cross validation in order to estimate the error of the model with respect to unseen data. The estimation is done by averaging the performance of the model over different subsets of the training set, divided into training and validation set. The function takes as input the number of splits, the features matrix and the target of the training set and the model. The function should return the R-squared and the train and the test root mean squared error normalized with respect to the variation of the target values (max value - min value). \n",
    "\n",
    "Hint: use KFold to split the training features matrix into train and validation.\n",
    "\n",
    "**Test(X_train, y_train, X_test, y_test, model)**:\n",
    "\n",
    "This function is used to train the model with all the training set and then to test the trained model with the test set. Use as metric the normalized root mean squared error (RMSE/(max(target value)-min(target value))) and the R-squared. The function takes as input the training test (features and target) and the test set (features and target).\n",
    "\n",
    "**Test_Train_Random(data)**:\n",
    "\n",
    "This fucntion should randomly give as output the indices of the original dataset that should belong to the training (80%) and test set (20%).\n",
    "\n",
    "Hint: use random.Random(1).shuffle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First of all split the original datas into train_set and test_set by using the indices provided by the Test_Train_Random function. After that divide the test and the training sets into X_train (for the features) / y_train (for the label) and the X_test (for the features) / y_test (for the label) respectively.**\n",
    "\n",
    "Hint: reset indices with reset_indx(drop=True) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initialize here 3 different models: DecisionTreeRegressor, RandomForestRegressor and AdaBoostRegressor. Remember to set the random_state parameter to a value in order to have repeatable results (see Scikit-Learn documentation). Using the Cross_Val function, with 10 splits, evaluate the prediction error estimation for the training set and the validation set. Then test your model using the Test function. In this operation store the feature importances for each model with the following commands:**\n",
    "\n",
    "feature_importance = model.feature_importances_\n",
    "\n",
    "**Answer the following questions:**\n",
    "\n",
    "### *Questions*\n",
    "- By using the Cross_Val function you have estimated the prediction error of the model in predicting the training labels and the validation labels. Which one is always bigger? Why?\n",
    "- How these two errors change according to the model used? Why? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of features importance\n",
    "Given the generated model, evaluate the contribution of each feature and see how the importance of such features change over the algorithms.\n",
    "\n",
    "**In this part you are asked to evaluate the importance of each feature. In the previous section you have stored the feature_importances_ for each model. Plot them using a bar plot and answer the following questions:**\n",
    "\n",
    "\n",
    "### *Questions*\n",
    "- Is the features contribution in each algorithm consistent?\n",
    "- Are the most important features coherent with a common interpretation? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Robustness Analysis\n",
    "\n",
    "**In this section you are asked to add noise to the features of the training set and then train the model with this noisy dataset. Then test the model with the test set and check whether how much the test error of each model is affected by the noise addition. Set the noise as follows:**\n",
    "\n",
    "noise = np.random.rand(X_train.shape[0])*val\n",
    "\n",
    "X_train_noisy = X_train.copy()\n",
    "\n",
    "for col in X_train.columns:\n",
    "\n",
    "        X_train_noisy[col] = X_train_noisy[col]+noise\n",
    "\n",
    "**where val should vary in the following range: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10].**\n",
    "\n",
    "**NB since it is a random noise, in order to have repeatable results use np.random.seed(seed_number) where you can set a specific seed_number.**\n",
    "\n",
    "**Plot the results for each model at each val value, and answer the following questions:**\n",
    "\n",
    "### *Questions*\n",
    "- How do the performances of each model change while increasing the noise? \n",
    "- Which algorithm is more affected by the addition of the noise? And which one is more robust?\n",
    "- Did you expect these results? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Optimization\n",
    "\n",
    "**In this section you are asked to optimize some hyperparameters of the models under analysis (Decision Tree, Random Forest and AdaBoost). For each hyperparameter you should define a set of values to test and then combine all the sets into a dictionary structure. Use the RandomizedSearchCV function to search the hyper-parameter space for the best cross validation score (see [documentation](https://scikit-learn.org/stable/modules/grid_search.html#grid-search)). Compare the results given by the best hyperparameters combination with respect to the default model.**\n",
    "\n",
    "### *Questions*\n",
    "- Can we improve the performance of the models by optimizing the hyperameters?\n",
    "- What is the bottleneck in the hyperparameters optimization? How would you handle this problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
